{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d145fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0f8c983",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM2(\n",
      "  (embed_tokens): Embedding(33, 1280, padding_idx=1)\n",
      "  (layers): ModuleList(\n",
      "    (0-32): 33 x TransformerLayer(\n",
      "      (self_attn): MultiheadAttention(\n",
      "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "        (rot_emb): RotaryEmbedding()\n",
      "      )\n",
      "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (contact_head): ContactPredictionHead(\n",
      "    (regression): Linear(in_features=660, out_features=1, bias=True)\n",
      "    (activation): Sigmoid()\n",
      "  )\n",
      "  (emb_layer_norm_after): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  (lm_head): RobertaLMHead(\n",
      "    (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from extract_contacts_and_attentions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116fe159",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dc2979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Libraries\n",
    "from Bio import SeqIO\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', PDBConstructionWarning)\n",
    "\n",
    "cos = nn.CosineSimilarity(dim=0, eps=1e-6)\n",
    "import esm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from Bio.PDB import PDBParser, PPBuilder\n",
    "from Bio.PDB.PDBExceptions import PDBConstructionWarning\n",
    "from Bio.SeqUtils import IUPACData\n",
    "\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import Bio.PDB\n",
    "import random\n",
    "import glob\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Set directories\n",
    "\n",
    "base_dir = '/Users/williamharrigan/Desktop/Github/contact_site_classifier/attention_classifier/data_files/'\n",
    "desktop = '/Users/williamharrigan/Desktop/'\n",
    "fasta_file = base_dir + 'rcsb_pdb_3KYN.fasta'\n",
    "pdb_filename = base_dir + '3kyn.pdb'\n",
    "structure_dir = base_dir +'structure_files/'\n",
    "fasta_dir = base_dir +'fasta_files/'\n",
    "casp_dir = '/Users/williamharrigan/Desktop/UH/Year_2/Research/contact_site_classifier/casp7/' \n",
    "casp_95 = casp_dir + 'training_95'\n",
    "\n",
    "# Get amino acid signature from 3 letter amino acid abbreviation\n",
    "\n",
    "def simple_aa(three_letter_code):\n",
    "    return IUPACData.protein_letters_3to1.get(three_letter_code.capitalize())\n",
    "\n",
    "\n",
    "def parse_casp7_file(file_path):\n",
    "    data_dict = {}\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line.startswith('[ID]'):\n",
    "                sequence_id = next(file).strip()\n",
    "            elif line.startswith('[PRIMARY]'):\n",
    "                sequence = next(file).strip()\n",
    "#                 print(sequence_id, sequence)\n",
    "                data_dict[sequence_id] = sequence\n",
    "\n",
    "    return data_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d96d089",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_pdb(pdb_id, structure_dir, downloadurl=\"http://files.rcsb.org/download/\"):\n",
    "    \"\"\"\n",
    "    Downloads a PDB file from the Internet and saves it in a data directory.\n",
    "    :param pdbcode: The standard PDB ID e.g. '3ICB' or '3icb'\n",
    "    :param datadir: The directory where the downloaded file will be saved\n",
    "    :param downloadurl: The base PDB download URL, cf.\n",
    "        `https://www.rcsb.org/pages/download/http#structures` for details\n",
    "        Note that the unencrypted HTTP protocol is used by default\n",
    "        to avoid spurious OpenSSL errors...\n",
    "    :return: the full path to the downloaded PDB file or None if something went wrong\n",
    "    \"\"\"\n",
    "    pdbfn = pdb_id + \".pdb\"\n",
    "    url = downloadurl + pdbfn\n",
    "    outfnm = os.path.join(structure_dir, pdbfn)\n",
    "    try:\n",
    "        urllib.request.urlretrieve(url, outfnm)\n",
    "        return pdbfn\n",
    "    except Exception as err:\n",
    "        # all sorts of things could have gone wrong...\n",
    "        print(str(err), file=sys.stderr)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd054cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_fasta(pdb_id, fasta_dir, downloadurl=\"https://www.rcsb.org/fasta/entry/\"):\n",
    "    pdbfn = pdb_id\n",
    "    url = downloadurl + pdbfn\n",
    "    outfnm = os.path.join(fasta_dir, F'{pdbfn}.fasta')\n",
    "    try:\n",
    "        urllib.request.urlretrieve(url, outfnm)\n",
    "        return pdbfn\n",
    "    except Exception as err:\n",
    "        # all sorts of things could have gone wrong...\n",
    "        print(str(err), file=sys.stderr)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738b7a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Take pdb_ids that occur only once in CASP7 dataset and generate fasta files \n",
    "# of sequences from pdb\n",
    "# Only sequences in first chain are taken to keep things simple down the line\n",
    "\n",
    "def generate_fastas(ids):\n",
    "    \n",
    "    protein_data = {}\n",
    "\n",
    "    for pdb_id in ids:\n",
    "        fasta_file = fasta_dir + pdb_id + '.fasta'\n",
    "        for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "#             print(record.id.split('|')[0].split('_')[0])\n",
    "#             print(len(str(record.seq)))\n",
    "            protein_data[record.id.split('|')[0].split('_')[0]] = str(record.seq)\n",
    "            break\n",
    "    return protein_data\n",
    "\n",
    "def load_fastas(fasta_dir):\n",
    "\n",
    "    protein_data = {}\n",
    "\n",
    "    for i in glob.glob(f'{fasta_dir}/*'):\n",
    "    #     pdb_id = i.split('/')[9].split('.')[0]\n",
    "        fasta_file = i\n",
    "        for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "#             print(record.id.split('|')[0].split('_')[0])\n",
    "#             print(len(str(record.seq)))\n",
    "            protein_data[record.id.split('|')[0].split('_')[0]] = str(record.seq)\n",
    "            break\n",
    "    return protein_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78e3bec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sequences(pdb_id):\n",
    "    warnings.simplefilter('ignore', PDBConstructionWarning)\n",
    "    parser = PDBParser()    \n",
    "    # Parse pdb file and save as structure. The pdb file is where we are getting CA coordinates from.\n",
    "    structure = parser.get_structure(pdb_id, f\"{structure_dir+pdb_id}.pdb\")\n",
    "\n",
    "    # Extract desired protein structure from PDB structure (typically only 1 structure to choose from)\n",
    "    protein_structure = structure[0]\n",
    "\n",
    "    residue_position = 0\n",
    "    mismatches = 0\n",
    "#     print(pdb_id)\n",
    "    if 'A' in protein_structure:\n",
    "        for residue in protein_structure['A']:\n",
    "            if 'CA' in residue:\n",
    "                if residue_position < len(protein_data[pdb_id]):\n",
    "                    if simple_aa(residue.resname) != protein_data[pdb_id][residue_position]:\n",
    "#                         print(residue.id[1], simple_aa(residue.resname), protein_data[pdb_id][residue_position])\n",
    "                        mismatches+=1\n",
    "            residue_position+=1\n",
    "        if mismatches == 0:\n",
    "#             same_sequence_ids.append(pdb_id)\n",
    "            return pdb_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27632559",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_casp_pdb_seqs(protein_data):\n",
    "    same_sequence_ids = []\n",
    "    iterations = 0\n",
    "    for pdb_id, protein_sequence in list(protein_data.items()):\n",
    "#         print(\"Iterations: \", iterations)\n",
    "#         print('Sequence ID: ', pdb_id)\n",
    "#         check_sequences(pdb_id)\n",
    "#         print('No mismatches in pdb sequence and pulled sequence: ', check_sequences(pdb_id))\n",
    "        if check_sequences(pdb_id) == None:\n",
    "            continue\n",
    "        else:\n",
    "            same_sequence_ids.append(pdb_id)\n",
    "        iterations+=1\n",
    "    return same_sequence_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88cf754",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_sequences('1H70') == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d921ce1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(same_sequence_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28caa60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_contact_sites(pdb_id, in_contact_sites, non_contact_sites, subset_non_contact_sites):\n",
    "    parser = PDBParser()\n",
    "    structure = parser.get_structure(pdb_id, f\"{structure_dir}/{pdb_id}.pdb\")  # Ensure correct path joining\n",
    "    protein_structure = structure[0]\n",
    "    chain = protein_structure['A']\n",
    "\n",
    "    # Initialize count variable\n",
    "    count = 0\n",
    "\n",
    "    for i, residue1 in enumerate(chain):\n",
    "        for j, residue2 in enumerate(chain):\n",
    "            if i <= j:\n",
    "                continue # Avoids redundant comparisons and self-comparison\n",
    "            if residue1.id[1] > len(protein_data[pdb_id]) or residue2.id[1] > len(protein_data[pdb_id]):\n",
    "                continue\n",
    "            try:\n",
    "                distance = abs(residue1['CA'] - residue2['CA'])\n",
    "            except KeyError:\n",
    "                continue\n",
    "            if distance < 5:\n",
    "                if abs(residue1.id[1] - residue2.id[1]) > 2:\n",
    "    #                 print(residue1.id[1], residue1.resname, residue2.id[1], residue2.resname, distance)\n",
    "                    in_contact_sites[pdb_id].append({\n",
    "                        'res_1': residue1.id[1], \n",
    "                        'res_2': residue2.id[1], \n",
    "                        'sig_1': simple_aa(residue1.resname), \n",
    "                        'sig_2': simple_aa(residue2.resname), \n",
    "                        'dist': distance,\n",
    "                        'in_contact': True\n",
    "                    })\n",
    "                    count += 1\n",
    "            else:\n",
    "                if abs(residue1.id[1] - residue2.id[1]) > 2:\n",
    "                    non_contact_sites[pdb_id].append({\n",
    "                        'res_1': residue1.id[1], \n",
    "                        'res_2': residue2.id[1], \n",
    "                        'sig_1': simple_aa(residue1.resname), \n",
    "                        'sig_2': simple_aa(residue2.resname), \n",
    "                        'dist': distance,\n",
    "                        'in_contact': False\n",
    "                    })\n",
    "\n",
    "    if non_contact_sites[pdb_id]:\n",
    "        subset_non_contact_sites[pdb_id] = random.sample(non_contact_sites[pdb_id], min(len(non_contact_sites[pdb_id]), len(in_contact_sites[pdb_id])))\n",
    "\n",
    "    # Optionally print or process the results\n",
    "    return f\"Total contacts found {pdb_id}: {count}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec0a2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contacts_per_pdb(same_sequence_ids):\n",
    "\n",
    "    in_contact_sites = defaultdict(list)\n",
    "    non_contact_sites = defaultdict(list)\n",
    "    subset_non_contact_sites = defaultdict(list)\n",
    "\n",
    "    iterations = 0\n",
    "\n",
    "    for pdb_id in same_sequence_ids:\n",
    "        calc_contact_sites(pdb_id, in_contact_sites, non_contact_sites, subset_non_contact_sites)\n",
    "#         print(calc_contact_sites(pdb_id, in_contact_sites, non_contact_sites, subset_non_contact_sites))\n",
    "#         print(len(in_contact_sites[pdb_id]), len(subset_non_contact_sites[pdb_id]))\n",
    "#         print(\"Iterations: \", iterations)\n",
    "        iterations+=1\n",
    "        \n",
    "    return in_contact_sites, non_contact_sites, subset_non_contact_sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c50b850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize contact_data as a defaultdict of lists\n",
    "\n",
    "def generate_contact_data(in_contact_sites, subset_non_contact_sites):\n",
    "\n",
    "    contact_data = defaultdict(list)\n",
    "\n",
    "    # Add data from in_contact_sites\n",
    "    for pdb_id, contacts in in_contact_sites.items():\n",
    "        for contact in contacts:\n",
    "            contact_data[pdb_id].append({\n",
    "                'res_1': contact['res_1'],\n",
    "                'res_2': contact['res_2'],\n",
    "                'sig_1': contact['sig_1'],\n",
    "                'sig_2': contact['sig_2'],\n",
    "                'dist': contact['dist'],\n",
    "                'in_contact': contact['in_contact']\n",
    "            })\n",
    "\n",
    "    # Add data from subset_non_contact_sites\n",
    "    for pdb_id, non_contacts in subset_non_contact_sites.items():\n",
    "        for non_contact in non_contacts:\n",
    "            contact_data[pdb_id].append({\n",
    "                'res_1': non_contact['res_1'],\n",
    "                'res_2': non_contact['res_2'],\n",
    "                'sig_1': non_contact['sig_1'],\n",
    "                'sig_2': non_contact['sig_2'],\n",
    "                'dist': non_contact['dist'],\n",
    "                'in_contact': non_contact['in_contact']\n",
    "            })\n",
    "    return contact_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2ab466",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(contact_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980ad3b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1. Load the ESM Model\n",
    "model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2b91f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model to use cuda GPU\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d53793c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index protein sequence as sequence 0 (next sequence would be indexed as 1)\n",
    "\n",
    "def generate_embeddings(pdb_id):\n",
    "    protein_sequence = protein_data[pdb_id]\n",
    "    esm_input_data = [(0, protein_sequence)]\n",
    "    # print('Data: ', esm_input_data, '\\n')\n",
    "\n",
    "    # Prepare variables to input sequence into ESM-2 model \n",
    "    batch_converter = alphabet.get_batch_converter()\n",
    "    batch_labels, batch_strs, batch_tokens = batch_converter(esm_input_data)\n",
    "    batch_tokens = batch_tokens.cuda() if torch.cuda.is_available() else batch_tokens\n",
    "\n",
    "    # print('batch_tokens: ', '\\n\\n', batch_tokens, '\\n')\n",
    "\n",
    "    # 4. Input prepared sequence information into model and output as results (contact predictions are included in embedding)\n",
    "    with torch.no_grad():\n",
    "        results = model(batch_tokens, repr_layers=[33], return_contacts=True)\n",
    "\n",
    "    return results['attentions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cd4a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract attentions from all heads and layers for given amino acid residues\n",
    "\n",
    "def get_x_y(attention_data, res_1, res_2):\n",
    "    vectors = []\n",
    "    for layer in range(0,33):\n",
    "        for head in range(0,20):\n",
    "            vectors.append(attention_data[0][layer][head][res_1][res_2])\n",
    "\n",
    "    return vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110c5ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_x_y(sequence_ids, contact_data):\n",
    "    X = []\n",
    "    y = []\n",
    "    iterations = 0\n",
    "\n",
    "    for pdb_id in sequence_ids:\n",
    "        structure = parser.get_structure(pdb_id, f\"{structure_dir}/{pdb_id}.pdb\")  # Ensure correct path joining\n",
    "        protein_structure = structure[0]\n",
    "        chain = protein_structure['A']\n",
    "        first_residue = list(chain.get_residues())[0].id[1]\n",
    "        print('Iteration: ', iterations)\n",
    "        iterations+=1\n",
    "        if first_residue == 1:\n",
    "            attention_data = generate_embeddings(pdb_id)\n",
    "            for i in contact_data[pdb_id]:\n",
    "                    X.append(get_x_y(attention_data, i['res_1'], i['res_2']))\n",
    "                    y.append(i['in_contact'])\n",
    "            else:\n",
    "                continue\n",
    "    return X,y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45619ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cf470f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get sequences from CASP7 file\n",
    "prot_data_dict = parse_casp7_file(casp_95)\n",
    "\n",
    "protein_id_counts = Counter(protein_id.split('_')[0] for protein_id in prot_data_dict)\n",
    "single_occurence_ids = [protein_id for protein_id, count in protein_id_counts.items() if count == 1]\n",
    "\n",
    "# protein_data = generate_fastas(single_occurence_ids)\n",
    "protein_data = load_fastas(fasta_dir)\n",
    "# same_sequence_ids = check_casp_pdb_seqs(protein_data)\n",
    "# in_contact_sites, non_contact_sites, subset_non_contact_sites = contacts_per_pdb(same_sequence_ids)\n",
    "# contact_data = generate_contact_data(in_contact_sites, subset_non_contact_sites)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5e2ede1",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore', PDBConstructionWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04aed38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "same_sequence_ids = check_casp_pdb_seqs(protein_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa3e6b2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parser' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m in_contact_sites, non_contact_sites, subset_non_contact_sites \u001b[38;5;241m=\u001b[39m contacts_per_pdb(same_sequence_ids)\n\u001b[1;32m      2\u001b[0m contact_data \u001b[38;5;241m=\u001b[39m generate_contact_data(in_contact_sites, subset_non_contact_sites)\n",
      "File \u001b[0;32m~/Desktop/Github/contact_site_classifier/attention_classifier/extract_contacts_and_attentions.py:233\u001b[0m, in \u001b[0;36mcontacts_per_pdb\u001b[0;34m(same_sequence_ids)\u001b[0m\n\u001b[1;32m    230\u001b[0m     iterations \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pdb_id \u001b[38;5;129;01min\u001b[39;00m same_sequence_ids:\n\u001b[0;32m--> 233\u001b[0m         calc_contact_sites(pdb_id, in_contact_sites, non_contact_sites, subset_non_contact_sites)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m#         print(calc_contact_sites(pdb_id, in_contact_sites, non_contact_sites, subset_non_contact_sites))\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m#         print(len(in_contact_sites[pdb_id]), len(subset_non_contact_sites[pdb_id]))\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;66;03m#         print(\"Iterations: \", iterations)\u001b[39;00m\n\u001b[1;32m    237\u001b[0m         iterations\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/Github/contact_site_classifier/attention_classifier/extract_contacts_and_attentions.py:178\u001b[0m, in \u001b[0;36mcalc_contact_sites\u001b[0;34m(pdb_id, in_contact_sites, non_contact_sites, subset_non_contact_sites)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalc_contact_sites\u001b[39m(pdb_id, in_contact_sites, non_contact_sites, subset_non_contact_sites):\n\u001b[0;32m--> 178\u001b[0m     structure \u001b[38;5;241m=\u001b[39m parser\u001b[38;5;241m.\u001b[39mget_structure(pdb_id, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstructure_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpdb_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pdb\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Ensure correct path joining\u001b[39;00m\n\u001b[1;32m    179\u001b[0m     protein_structure \u001b[38;5;241m=\u001b[39m structure[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    180\u001b[0m     chain \u001b[38;5;241m=\u001b[39m protein_structure[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'parser' is not defined"
     ]
    }
   ],
   "source": [
    "in_contact_sites, non_contact_sites, subset_non_contact_sites = contacts_per_pdb(same_sequence_ids)\n",
    "contact_data = generate_contact_data(in_contact_sites, subset_non_contact_sites)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0680c05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51365ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 67\n",
    "random.seed(seed_value)\n",
    "n_sequences = 10\n",
    "\n",
    "sequence_ids = random.sample(same_sequence_ids, n_sequences)\n",
    "\n",
    "print(sequence_ids[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9835a57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = output_x_y(sequence_ids, contact_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
