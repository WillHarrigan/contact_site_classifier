{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41fbe97c",
   "metadata": {},
   "source": [
    "# Extracting distance between amino acids, contacts and attentions to train and test ML classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2a5351",
   "metadata": {},
   "source": [
    "## Import .py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d52583c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM2(\n",
      "  (embed_tokens): Embedding(33, 1280, padding_idx=1)\n",
      "  (layers): ModuleList(\n",
      "    (0-32): 33 x TransformerLayer(\n",
      "      (self_attn): MultiheadAttention(\n",
      "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "        (rot_emb): RotaryEmbedding()\n",
      "      )\n",
      "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
      "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
      "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (contact_head): ContactPredictionHead(\n",
      "    (regression): Linear(in_features=660, out_features=1, bias=True)\n",
      "    (activation): Sigmoid()\n",
      "  )\n",
      "  (emb_layer_norm_after): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  (lm_head): RobertaLMHead(\n",
      "    (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
      "    (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Set path to directory containing .py files\n",
    "# Import .py file to extract distance between amino acids, contacts and attentions\n",
    "# All necessary packages are imported within the .py file\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../py\")\n",
    "\n",
    "# ESM-2 model for protein embeddings is esm.pretrained.esm2_t33_650M_UR50D()\n",
    "from extract_contact_aa_distance_attentions import * \n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e049e7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings when importing PDB structure files\n",
    "warnings.simplefilter('ignore', PDBConstructionWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "# Set variable for parsing PDB structural files\n",
    "parser = PDBParser()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01759d16",
   "metadata": {},
   "source": [
    "## Extract Sequences from CASP7 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f6932a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1RSO_2_B\n",
      "GLLAAERAVSQVLDSLEEIHALTDSSEKDLDFLHSVFQDQHLHTLLDLYDKINTKS\n",
      "\n",
      "3PCG_1_A\n",
      "PIELLPETPSQTAGPYVHIGLALEAAGNPTRDQEIWNRLAKPDAPGEHILLLGQVYDGNGHLVRDSFLEVWQADANGEYQDAYNLENAFNSFGRTATTFDAGEWTLHTVKPGVVNNAAGVPMAPHINISLFARGINIHLHTRLYFDDEAQANAKCPVLNLIEQPQRRETLIAKRCEVDGKTAYRFDIRIQGEGETVFFDF\n",
      "\n",
      "1YBD_1_A\n",
      "MTQQIKYKRVLLKLSGESLMGSDPFGINHDTIVQTVGEIAEVVKMGVQVGIVVGGGNIFRGVSAQAGSMDRATADYMGMMATVMNALALKDAFETLGIKARVQSALSMQQIAETYARPKAIQYLEEGKVVIFAAGTGNPFFTTDTAAALRGAEMNCDVMLKATNVDGVYTADPKKDPSATRYETITFDEALLKNLKVMDATAFALCRERKLNIVVFGIAKEGSLKRVITGEDEGTLVHC\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Make sure to update directory paths from .py file prior to executing code\n",
    "\n",
    "# Parse CASP training_95 file, extract all sequence IDs and sequences from dataset\n",
    "# CASP training_95 file contains seed sequences for sequence clusters at 95% similarity\n",
    "\n",
    "prot_data_dict = parse_casp7_file(casp_95)\n",
    "\n",
    "for casp_id, casp_seq in list(prot_data_dict.items())[:3]:\n",
    "    print(casp_id)\n",
    "    print(casp_seq)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d05b429d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Unique IDs:  8494 \n",
      "\n",
      "['1YBD', '1PSM', '1DM0', '1WFO', '1YOA']\n"
     ]
    }
   ],
   "source": [
    "# CASP datasets contains sequence IDs that correspond to different chains in a sequence\n",
    "# I.E. 1RSO_2_B refers to the 2nd part of chain B of the protein 1RSO\n",
    "\n",
    "## To be sure I extract the CASP sequence that corresponds to the sequence in the \n",
    "# PDB structural file, I extract CASP IDs that occur once\n",
    "# Which means that the stored sequence is the entire sequence for the protein\n",
    "# This is because some sequences in the dataset only have a label for 1 chain\n",
    "\n",
    "# Calculate occurence of sequence IDs\n",
    "protein_id_counts = Counter(protein_id.split('_')[0] for protein_id in prot_data_dict)\n",
    "\n",
    "# Store IDs that only occur once as single_occurence_ids\n",
    "single_occurence_ids = [protein_id for protein_id, count in protein_id_counts.items() if count == 1]\n",
    "\n",
    "print('Number of Unique IDs: ', len(single_occurence_ids), '\\n')\n",
    "print(single_occurence_ids[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f456af4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'1R4Q' in prot_data_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f613ded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52668cd0",
   "metadata": {},
   "source": [
    "## Extract FASTA files from PDB database from identified CASP Protein IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb555165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Sequences:  2682 \n",
      "\n",
      "1C4R\n",
      "GHAGTTYIFSKGGGQITYKWPPNDRPSTRADRLAIGFSTVQKEAVLVRVDSSSGLGDYLELHIHQGKIGVKFNVGTDDIAIEESNAIINDGKYHVVRFTRSGGNATLQVDSWPVIERYPAGRQLTIFNSQATIIIGGKEQGQPFQGQLSGLYYNGLKVLNMAAENDANIAIVGNVRLVGEVP\n",
      "\n",
      "1UE8\n",
      "MYDWFKQMRKESPVYYDGKVWNLFKYEDCKMVLNDHKRFSSNLTGYNDKLEMLRSGKVFFDIPTRYTMLTSDPPLHDELRNLTADAFNPSNLPVDFVREVTVKLLSELDEEFDVIESFAIPLPILVISKMLGINPDVKKVKDWSDLVALRLGRADEIFSIGRKYLELISFSKKELDSRKGKEIVDLTGKIANSNLSELEKEGYFILLMIAGNETTTNLIGNAIEDFTLYNSWDYVREKGALKAVEEALRFSPPVMRTIRVTKEKVKIRDQVIDEGELVRVWIASANRDEEVFKDPDSFIPDRTPNPHLSFGSGIHLCLGAPLARLEARIALEEFAKKFRVKEIVKKEKIDNEVLNGYRKLVVRVERT\n",
      "\n",
      "1I24\n",
      "MRGSHHHHHHGSRVMVIGGDGYCGWATALHLSKKNYEVCIVDNLVRRLFDHQLGLESLTPIASIHDRISRWKALTGKSIELYVGDICDFEFLAESFKSFEPDSVVHFGEQRSAPYSMIDRSRAVYTQHNNVIGTLNVLFAIKEFGEECHLVKLGTMGEYGTPNIDIEEGYITITHNGRTDTLPYPKQASSFYHLSKVHDSHNIAFTCKAWGIRATDLNQGVVYGVKTDETEMHEELRNRLDYDAVFGTALNRFCVQAAVGHPLTVYGKGGQTRGYLDIRDTVQCVEIAIANPAKAGEFRVFNQFTEQFSVNELASLVTKAGSKLGLDVKKMTVPNPRVEAEEHYYNAKHTKLMELGLEPHYLSDSLLDSLLNFAVQFKDRVDTKQIMPSVSWKKIGVKTKSMTT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Take the IDs that occur once in the CASP training_95 dataset and extract the sequences\n",
    "# from the PDB database. These sequences are used in generating PDB structural data.\n",
    "# I.E. calculating arnstrong distance.\n",
    "\n",
    "# for pdb_id in single_occurence_ids:\n",
    "#     download_fasta(pdb_id, fasta_dir, downloadurl=\"https://www.rcsb.org/fasta/entry/\")\n",
    "\n",
    "# Load sequence ID and sequences from PDB into a dictionary\n",
    "protein_data = load_fastas(fasta_dir)\n",
    "\n",
    "print('Number of Sequences: ', len(protein_data), '\\n')\n",
    "\n",
    "for pdb_id, pdb_seq in list(protein_data.items())[:3]:\n",
    "    print(pdb_id)\n",
    "    print(pdb_seq)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b6fffd",
   "metadata": {},
   "source": [
    "## Extract sequences that are the same in PDB database and CASP dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee8cb36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Uniform Sequences:  1215 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Store sequence IDs that have sequences that are the same in both PDB database and\n",
    "# CASP training_95 dataset\n",
    "# Double checking if the sequences are uniform is important to ensure we are comparing\n",
    "# the same proteins and chains that are the seed sequences in the CASP dataset clusters\n",
    "\n",
    "same_sequence_ids = check_casp_pdb_seqs(protein_data)\n",
    "\n",
    "print('Number of Uniform Sequences: ', len(same_sequence_ids), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39027f59",
   "metadata": {},
   "source": [
    "## Extract PDB structural data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9828f6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Takes pdb_ids that have been extracted above and downloads the pdb structural file from\n",
    "# the pdb database.\n",
    "# These files will be used when generating contact sites.\n",
    "\n",
    "\n",
    "# for pdb_id in same_sequence_ids:\n",
    "#     download_pdb(pdb_id, structure_dir, downloadurl=\"http://files.rcsb.org/download/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92b2ce9",
   "metadata": {},
   "source": [
    "## Calculate distance between amino acids in the sequence and arnstrong distance between amino acids from PDB structural file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "415c2a06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'res_1': 215, 'res_2': 212, 'sig_1': 'T', 'sig_2': 'N', 'aa_dist': 3, 'arn_dist': 4.8835087, 'in_contact': True}\n",
      "{'res_1': 274, 'res_2': 264, 'sig_1': 'E', 'sig_2': 'K', 'aa_dist': 10, 'arn_dist': 4.846522, 'in_contact': True}\n",
      "{'res_1': 282, 'res_2': 256, 'sig_1': 'I', 'sig_2': 'R', 'aa_dist': 26, 'arn_dist': 4.9069557, 'in_contact': True}\n",
      "{'res_1': 155, 'res_2': 54, 'sig_1': 'D', 'sig_2': 'R', 'aa_dist': 101, 'arn_dist': 26.104069, 'in_contact': False}\n",
      "{'res_1': 148, 'res_2': 120, 'sig_1': 'A', 'sig_2': 'I', 'aa_dist': 28, 'arn_dist': 13.640676, 'in_contact': False}\n",
      "{'res_1': 325, 'res_2': 300, 'sig_1': 'L', 'sig_2': 'P', 'aa_dist': 25, 'arn_dist': 16.530783, 'in_contact': False}\n"
     ]
    }
   ],
   "source": [
    "## To make sure we have a balanced number of contacts and non-contacts for each protein\n",
    "# We make a subset of non-contact sites that are randomly selected and\n",
    "# has the same number of amino acid pairs as in-contact sites\n",
    "\n",
    "in_contact_sites, non_contact_sites, subset_non_contact_sites = contacts_per_pdb(same_sequence_ids,protein_data)\n",
    "\n",
    "# Assuming in_contact_sites and subset_non_contact_sites are dictionaries\n",
    "for sequence_id_in_contact, sequence_id_non_contact in zip(list(in_contact_sites.keys())[:1], list(subset_non_contact_sites.keys())[:1]):\n",
    "    # If you want to process only 'in_contact_sites'\n",
    "    for instance in random.sample(in_contact_sites[sequence_id_in_contact], 3):\n",
    "        print(instance)\n",
    "\n",
    "for instance in random.sample(subset_non_contact_sites[sequence_id_non_contact], 3):\n",
    "    print(instance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "620acc09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences:  1102\n"
     ]
    }
   ],
   "source": [
    "# Store in_contact dictionary and subset of non_contact dictionary as a single dictionary\n",
    "# which will be used in ML train/test split\n",
    "\n",
    "# Some sequences chains that are found to have no contacts are removed from the dictionary\n",
    "\n",
    "contact_data = generate_contact_data(in_contact_sites, subset_non_contact_sites)\n",
    "\n",
    "print('Number of sequences: ', len(contact_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a69b9c",
   "metadata": {},
   "source": [
    "## Collect X, y data for ML model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0072dc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_sequences:  300\n",
      "['1BUE', '1FK5', '1QK9', '1PPQ', '1T5Q']\n"
     ]
    }
   ],
   "source": [
    "# Randomly select sequences from same_sequence_ids to reduce computational demand for training\n",
    "seed_value = 67\n",
    "random.seed(seed_value)\n",
    "n_sequences = 300\n",
    "\n",
    "sequence_ids = random.sample(same_sequence_ids, n_sequences)\n",
    "# sequence_ids = same_sequence_ids\n",
    "print('n_sequences: ', n_sequences)\n",
    "print(sequence_ids[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0355308",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "Iteration:  1\n",
      "Iteration:  2\n",
      "Iteration:  3\n",
      "Iteration:  4\n",
      "Iteration:  5\n",
      "Iteration:  6\n",
      "Iteration:  7\n",
      "Iteration:  8\n",
      "Iteration:  9\n",
      "Iteration:  10\n",
      "Iteration:  11\n",
      "Iteration:  12\n",
      "Iteration:  13\n",
      "Iteration:  14\n",
      "Iteration:  15\n",
      "Iteration:  16\n",
      "Iteration:  17\n",
      "Iteration:  18\n",
      "Iteration:  19\n",
      "Iteration:  20\n",
      "Iteration:  21\n",
      "Iteration:  22\n",
      "Iteration:  23\n",
      "Iteration:  24\n",
      "Iteration:  25\n",
      "Iteration:  26\n",
      "Iteration:  27\n",
      "Iteration:  28\n",
      "Iteration:  29\n",
      "Iteration:  30\n",
      "Iteration:  31\n",
      "Iteration:  32\n",
      "Iteration:  33\n",
      "Iteration:  34\n",
      "Iteration:  35\n",
      "Iteration:  36\n",
      "Iteration:  37\n",
      "Iteration:  38\n",
      "Iteration:  39\n",
      "Iteration:  40\n",
      "Iteration:  41\n",
      "Iteration:  42\n",
      "Iteration:  43\n",
      "Iteration:  44\n",
      "Iteration:  45\n",
      "Iteration:  46\n",
      "Iteration:  47\n",
      "Iteration:  48\n",
      "Iteration:  49\n",
      "Iteration:  50\n",
      "Iteration:  51\n",
      "Iteration:  52\n",
      "Iteration:  53\n",
      "Iteration:  54\n",
      "Iteration:  55\n",
      "Iteration:  56\n",
      "Iteration:  57\n",
      "Iteration:  58\n",
      "Iteration:  59\n",
      "Iteration:  60\n",
      "Iteration:  61\n",
      "Iteration:  62\n",
      "Iteration:  63\n",
      "Iteration:  64\n",
      "Iteration:  65\n",
      "Iteration:  66\n",
      "Iteration:  67\n",
      "Iteration:  68\n",
      "Iteration:  69\n",
      "Iteration:  70\n",
      "Iteration:  71\n",
      "Iteration:  72\n",
      "Iteration:  73\n",
      "Iteration:  74\n",
      "Iteration:  75\n",
      "Iteration:  76\n",
      "Iteration:  77\n",
      "Iteration:  78\n",
      "Iteration:  79\n",
      "Iteration:  80\n",
      "Iteration:  81\n",
      "Iteration:  82\n",
      "Iteration:  83\n",
      "Iteration:  84\n",
      "Iteration:  85\n",
      "Iteration:  86\n",
      "Iteration:  87\n",
      "Iteration:  88\n",
      "Iteration:  89\n",
      "Iteration:  90\n",
      "Iteration:  91\n",
      "Iteration:  92\n",
      "Iteration:  93\n",
      "Iteration:  94\n",
      "Iteration:  95\n",
      "Iteration:  96\n",
      "Iteration:  97\n",
      "Iteration:  98\n",
      "Iteration:  99\n",
      "Iteration:  100\n",
      "Iteration:  101\n",
      "Iteration:  102\n",
      "Iteration:  103\n",
      "Iteration:  104\n",
      "Iteration:  105\n",
      "Iteration:  106\n",
      "Iteration:  107\n",
      "Iteration:  108\n",
      "Iteration:  109\n",
      "Iteration:  110\n",
      "Iteration:  111\n",
      "Iteration:  112\n",
      "Iteration:  113\n",
      "Iteration:  114\n",
      "Iteration:  115\n",
      "Iteration:  116\n",
      "Iteration:  117\n",
      "Iteration:  118\n",
      "Iteration:  119\n",
      "Iteration:  120\n",
      "Iteration:  121\n",
      "Iteration:  122\n",
      "Iteration:  123\n",
      "Iteration:  124\n",
      "Iteration:  125\n",
      "Iteration:  126\n",
      "Iteration:  127\n",
      "Iteration:  128\n",
      "Iteration:  129\n",
      "Iteration:  130\n",
      "Iteration:  131\n",
      "Iteration:  132\n",
      "Iteration:  133\n",
      "Iteration:  134\n",
      "Iteration:  135\n",
      "Iteration:  136\n",
      "Iteration:  137\n",
      "Iteration:  138\n",
      "Iteration:  139\n",
      "Iteration:  140\n",
      "Iteration:  141\n",
      "Iteration:  142\n",
      "Iteration:  143\n",
      "Iteration:  144\n",
      "Iteration:  145\n",
      "Iteration:  146\n",
      "Iteration:  147\n",
      "Iteration:  148\n",
      "Iteration:  149\n",
      "Iteration:  150\n",
      "Iteration:  151\n",
      "Iteration:  152\n",
      "Iteration:  153\n",
      "Iteration:  154\n",
      "Iteration:  155\n",
      "Iteration:  156\n",
      "Iteration:  157\n",
      "Iteration:  158\n",
      "Iteration:  159\n",
      "Iteration:  160\n",
      "Iteration:  161\n",
      "Iteration:  162\n",
      "Iteration:  163\n",
      "Iteration:  164\n",
      "Iteration:  165\n",
      "Iteration:  166\n",
      "Iteration:  167\n",
      "Iteration:  168\n",
      "Iteration:  169\n",
      "Iteration:  170\n",
      "Iteration:  171\n",
      "Iteration:  172\n",
      "Iteration:  173\n",
      "Iteration:  174\n",
      "Iteration:  175\n",
      "Iteration:  176\n",
      "Iteration:  177\n",
      "Iteration:  178\n",
      "Iteration:  179\n",
      "Iteration:  180\n",
      "Iteration:  181\n",
      "Iteration:  182\n",
      "Iteration:  183\n",
      "Iteration:  184\n",
      "Iteration:  185\n",
      "Iteration:  186\n",
      "Iteration:  187\n",
      "Iteration:  188\n",
      "Iteration:  189\n",
      "Iteration:  190\n",
      "Iteration:  191\n",
      "Iteration:  192\n",
      "Iteration:  193\n",
      "Iteration:  194\n",
      "Iteration:  195\n",
      "Iteration:  196\n",
      "Iteration:  197\n",
      "Iteration:  198\n",
      "Iteration:  199\n",
      "Iteration:  200\n",
      "Iteration:  201\n",
      "Iteration:  202\n",
      "Iteration:  203\n",
      "Iteration:  204\n",
      "Iteration:  205\n",
      "Iteration:  206\n",
      "Iteration:  207\n",
      "Iteration:  208\n",
      "Iteration:  209\n",
      "Iteration:  210\n",
      "Iteration:  211\n",
      "Iteration:  212\n",
      "Iteration:  213\n",
      "Iteration:  214\n",
      "Iteration:  215\n",
      "Iteration:  216\n",
      "Iteration:  217\n",
      "Iteration:  218\n",
      "Iteration:  219\n",
      "Iteration:  220\n",
      "Iteration:  221\n",
      "Iteration:  222\n",
      "Iteration:  223\n",
      "Iteration:  224\n",
      "Iteration:  225\n",
      "Iteration:  226\n",
      "Iteration:  227\n",
      "Iteration:  228\n",
      "Iteration:  229\n",
      "Iteration:  230\n",
      "Iteration:  231\n",
      "Iteration:  232\n",
      "Iteration:  233\n",
      "Iteration:  234\n",
      "Iteration:  235\n",
      "Iteration:  236\n",
      "Iteration:  237\n",
      "Iteration:  238\n",
      "Iteration:  239\n",
      "Iteration:  240\n",
      "Iteration:  241\n",
      "Iteration:  242\n",
      "Iteration:  243\n",
      "Iteration:  244\n",
      "Iteration:  245\n",
      "Iteration:  246\n",
      "Iteration:  247\n",
      "Iteration:  248\n",
      "Iteration:  249\n",
      "Iteration:  250\n",
      "Iteration:  251\n",
      "Iteration:  252\n",
      "Iteration:  253\n",
      "Iteration:  254\n",
      "Iteration:  255\n",
      "Iteration:  256\n",
      "Iteration:  257\n",
      "Iteration:  258\n",
      "Iteration:  259\n",
      "Iteration:  260\n",
      "Iteration:  261\n",
      "Iteration:  262\n",
      "Iteration:  263\n",
      "Iteration:  264\n",
      "Iteration:  265\n",
      "Iteration:  266\n",
      "Iteration:  267\n",
      "Iteration:  268\n",
      "Iteration:  269\n",
      "Iteration:  270\n",
      "Iteration:  271\n",
      "Iteration:  272\n",
      "Iteration:  273\n",
      "Iteration:  274\n",
      "Iteration:  275\n",
      "Iteration:  276\n",
      "Iteration:  277\n",
      "Iteration:  278\n",
      "Iteration:  279\n",
      "Iteration:  280\n",
      "Iteration:  281\n",
      "Iteration:  282\n",
      "Iteration:  283\n",
      "Iteration:  284\n",
      "Iteration:  285\n",
      "Iteration:  286\n",
      "Iteration:  287\n",
      "Iteration:  288\n",
      "Iteration:  289\n",
      "Iteration:  290\n",
      "Iteration:  291\n",
      "Iteration:  292\n",
      "Iteration:  293\n",
      "Iteration:  294\n",
      "Iteration:  295\n",
      "Iteration:  296\n",
      "Iteration:  297\n",
      "Iteration:  298\n",
      "Iteration:  299\n"
     ]
    }
   ],
   "source": [
    "# The following function takes sequence IDs, generates ESM-2 embeddings, takes instances\n",
    "# from contact_data, extracts combinations of residue 1 and residue 2, extracts attentions\n",
    "# from all of the layers and heads for these combinations and extracts whether the residues \n",
    "# are in contact or not from earlier arnstrong distance calculations. \n",
    "\n",
    "# Attention vectors are stored as X, and residue contact values (True/False) are stored as Y\n",
    "# Iterations represent how many sequences have been iterated through in the function\n",
    "# Iterations = n_sequences\n",
    "\n",
    "X, y = output_x_y(sequence_ids, contact_data, protein_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bcff44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Amino Acid Instances:  9699\n",
      "Number of positive instances:  4850\n"
     ]
    }
   ],
   "source": [
    "# Train/Test split\n",
    "# Previous experiment suggests test_size = 0.4 is optimal for best performance\n",
    "# Due to subseting non-contact instances to be = to in-contact instances\n",
    "# number of positive cases == number of negative cases\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.4, random_state=42)\n",
    "\n",
    "print('Number of Amino Acid Instances: ', len(X_train))\n",
    "print('Number of positive instances: ', round(len(X_train)/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eeda3e72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.0183),\n",
       " tensor(0.0051),\n",
       " tensor(0.0120),\n",
       " tensor(0.0068),\n",
       " tensor(0.0118),\n",
       " tensor(0.0155),\n",
       " tensor(0.0064),\n",
       " tensor(0.0090),\n",
       " tensor(0.0034),\n",
       " tensor(0.0173),\n",
       " tensor(0.0148),\n",
       " tensor(0.0172),\n",
       " tensor(0.0117),\n",
       " tensor(0.0131),\n",
       " tensor(0.0041),\n",
       " tensor(0.0080),\n",
       " tensor(0.0159),\n",
       " tensor(0.0095),\n",
       " tensor(0.0098),\n",
       " tensor(0.0022),\n",
       " tensor(4.2884e-05),\n",
       " tensor(3.5786e-07),\n",
       " tensor(0.0056),\n",
       " tensor(0.0048),\n",
       " tensor(0.0065),\n",
       " tensor(0.0187),\n",
       " tensor(0.0088),\n",
       " tensor(3.2372e-08),\n",
       " tensor(2.3364e-09),\n",
       " tensor(0.0060),\n",
       " tensor(0.0048),\n",
       " tensor(0.0418),\n",
       " tensor(0.0033),\n",
       " tensor(0.0052),\n",
       " tensor(0.0041),\n",
       " tensor(0.0001),\n",
       " tensor(4.3949e-08),\n",
       " tensor(0.0312),\n",
       " tensor(0.1279),\n",
       " tensor(0.0102),\n",
       " tensor(0.0062),\n",
       " tensor(0.0021),\n",
       " tensor(0.0010),\n",
       " tensor(0.0174),\n",
       " tensor(0.0002),\n",
       " tensor(0.1701),\n",
       " tensor(0.0071),\n",
       " tensor(0.0150),\n",
       " tensor(0.0113),\n",
       " tensor(0.0110),\n",
       " tensor(0.0267),\n",
       " tensor(0.0010),\n",
       " tensor(0.0045),\n",
       " tensor(0.0032),\n",
       " tensor(0.0035),\n",
       " tensor(0.0107),\n",
       " tensor(0.0015),\n",
       " tensor(1.5704e-07),\n",
       " tensor(2.1547e-05),\n",
       " tensor(0.0061),\n",
       " tensor(0.0028),\n",
       " tensor(0.0018),\n",
       " tensor(0.0056),\n",
       " tensor(0.0093),\n",
       " tensor(0.0042),\n",
       " tensor(0.0127),\n",
       " tensor(0.0187),\n",
       " tensor(0.0098),\n",
       " tensor(0.0344),\n",
       " tensor(0.0083),\n",
       " tensor(7.5494e-05),\n",
       " tensor(1.4479e-07),\n",
       " tensor(0.0051),\n",
       " tensor(0.0027),\n",
       " tensor(0.0052),\n",
       " tensor(8.0859e-06),\n",
       " tensor(0.0006),\n",
       " tensor(0.0178),\n",
       " tensor(0.0191),\n",
       " tensor(0.0050),\n",
       " tensor(0.0037),\n",
       " tensor(0.0046),\n",
       " tensor(0.0002),\n",
       " tensor(0.0037),\n",
       " tensor(0.0094),\n",
       " tensor(0.0027),\n",
       " tensor(0.0093),\n",
       " tensor(0.0050),\n",
       " tensor(0.0031),\n",
       " tensor(0.0049),\n",
       " tensor(0.0018),\n",
       " tensor(0.0222),\n",
       " tensor(0.0088),\n",
       " tensor(0.0151),\n",
       " tensor(0.0079),\n",
       " tensor(0.0011),\n",
       " tensor(0.3753),\n",
       " tensor(0.0014),\n",
       " tensor(0.0093),\n",
       " tensor(0.0077),\n",
       " tensor(0.0066),\n",
       " tensor(0.0019),\n",
       " tensor(0.0062),\n",
       " tensor(0.0165),\n",
       " tensor(0.0026),\n",
       " tensor(0.0425),\n",
       " tensor(0.0215),\n",
       " tensor(0.0023),\n",
       " tensor(0.0186),\n",
       " tensor(0.0062),\n",
       " tensor(0.0119),\n",
       " tensor(0.0052),\n",
       " tensor(0.0065),\n",
       " tensor(0.0026),\n",
       " tensor(0.0082),\n",
       " tensor(0.0077),\n",
       " tensor(0.0197),\n",
       " tensor(0.0053),\n",
       " tensor(0.0255),\n",
       " tensor(0.0023),\n",
       " tensor(0.0106),\n",
       " tensor(0.0060),\n",
       " tensor(0.0131),\n",
       " tensor(0.0145),\n",
       " tensor(0.0045),\n",
       " tensor(0.0029),\n",
       " tensor(0.0246),\n",
       " tensor(0.0063),\n",
       " tensor(0.0041),\n",
       " tensor(0.0072),\n",
       " tensor(0.0016),\n",
       " tensor(0.0045),\n",
       " tensor(0.1084),\n",
       " tensor(0.0050),\n",
       " tensor(0.0064),\n",
       " tensor(0.0008),\n",
       " tensor(0.0053),\n",
       " tensor(0.0158),\n",
       " tensor(0.0003),\n",
       " tensor(0.0033),\n",
       " tensor(0.0069),\n",
       " tensor(0.0287),\n",
       " tensor(0.0724),\n",
       " tensor(0.0040),\n",
       " tensor(0.0047),\n",
       " tensor(0.0015),\n",
       " tensor(0.0165),\n",
       " tensor(0.0018),\n",
       " tensor(0.0285),\n",
       " tensor(0.0053),\n",
       " tensor(0.0070),\n",
       " tensor(0.0050),\n",
       " tensor(0.0121),\n",
       " tensor(0.0001),\n",
       " tensor(0.0039),\n",
       " tensor(0.0078),\n",
       " tensor(0.0003),\n",
       " tensor(0.0112),\n",
       " tensor(0.0048),\n",
       " tensor(0.0195),\n",
       " tensor(7.1701e-07),\n",
       " tensor(0.0137),\n",
       " tensor(0.0251),\n",
       " tensor(0.0141),\n",
       " tensor(0.0090),\n",
       " tensor(0.0002),\n",
       " tensor(0.0006),\n",
       " tensor(0.0164),\n",
       " tensor(0.0374),\n",
       " tensor(0.0145),\n",
       " tensor(0.0015),\n",
       " tensor(0.0081),\n",
       " tensor(0.0080),\n",
       " tensor(0.0220),\n",
       " tensor(0.0146),\n",
       " tensor(0.0052),\n",
       " tensor(0.0059),\n",
       " tensor(0.0038),\n",
       " tensor(0.0085),\n",
       " tensor(0.0023),\n",
       " tensor(0.0092),\n",
       " tensor(0.0028),\n",
       " tensor(0.0098),\n",
       " tensor(0.0005),\n",
       " tensor(0.0053),\n",
       " tensor(0.0128),\n",
       " tensor(0.0495),\n",
       " tensor(0.0107),\n",
       " tensor(0.0022),\n",
       " tensor(0.0094),\n",
       " tensor(0.0036),\n",
       " tensor(0.0026),\n",
       " tensor(0.0102),\n",
       " tensor(0.0041),\n",
       " tensor(5.4522e-05),\n",
       " tensor(0.0072),\n",
       " tensor(0.0120),\n",
       " tensor(0.0065),\n",
       " tensor(0.0054),\n",
       " tensor(0.0042),\n",
       " tensor(0.0002),\n",
       " tensor(0.0100),\n",
       " tensor(0.0089),\n",
       " tensor(0.0003),\n",
       " tensor(0.0107),\n",
       " tensor(1.7277e-08),\n",
       " tensor(0.0140),\n",
       " tensor(0.0143),\n",
       " tensor(0.0129),\n",
       " tensor(0.0002),\n",
       " tensor(0.0104),\n",
       " tensor(0.0022),\n",
       " tensor(0.0079),\n",
       " tensor(0.0064),\n",
       " tensor(0.0064),\n",
       " tensor(0.0037),\n",
       " tensor(0.0097),\n",
       " tensor(7.9239e-07),\n",
       " tensor(0.0070),\n",
       " tensor(0.0044),\n",
       " tensor(0.0001),\n",
       " tensor(0.0067),\n",
       " tensor(0.0091),\n",
       " tensor(0.0034),\n",
       " tensor(0.0113),\n",
       " tensor(0.0039),\n",
       " tensor(0.0075),\n",
       " tensor(0.0057),\n",
       " tensor(0.0046),\n",
       " tensor(0.0256),\n",
       " tensor(0.0064),\n",
       " tensor(0.0309),\n",
       " tensor(0.0219),\n",
       " tensor(0.0056),\n",
       " tensor(0.0041),\n",
       " tensor(0.0085),\n",
       " tensor(0.0028),\n",
       " tensor(0.0085),\n",
       " tensor(0.0018),\n",
       " tensor(0.0122),\n",
       " tensor(0.0013),\n",
       " tensor(0.0020),\n",
       " tensor(0.0083),\n",
       " tensor(0.0021),\n",
       " tensor(0.0098),\n",
       " tensor(1.3468e-05),\n",
       " tensor(0.0043),\n",
       " tensor(0.0063),\n",
       " tensor(0.0050),\n",
       " tensor(0.0187),\n",
       " tensor(0.1610),\n",
       " tensor(0.0058),\n",
       " tensor(0.0059),\n",
       " tensor(0.0077),\n",
       " tensor(0.0144),\n",
       " tensor(0.0014),\n",
       " tensor(0.0105),\n",
       " tensor(0.0009),\n",
       " tensor(0.0080),\n",
       " tensor(0.0305),\n",
       " tensor(0.0005),\n",
       " tensor(0.0023),\n",
       " tensor(0.0065),\n",
       " tensor(0.0112),\n",
       " tensor(0.0340),\n",
       " tensor(1.6154e-09),\n",
       " tensor(0.0066),\n",
       " tensor(0.0010),\n",
       " tensor(0.0029),\n",
       " tensor(2.9024e-08),\n",
       " tensor(0.0030),\n",
       " tensor(0.0207),\n",
       " tensor(0.0049),\n",
       " tensor(0.0045),\n",
       " tensor(0.0095),\n",
       " tensor(0.0017),\n",
       " tensor(0.0025),\n",
       " tensor(0.0176),\n",
       " tensor(0.0013),\n",
       " tensor(0.0039),\n",
       " tensor(0.0013),\n",
       " tensor(0.0066),\n",
       " tensor(0.0616),\n",
       " tensor(0.0061),\n",
       " tensor(0.0106),\n",
       " tensor(3.0240e-07),\n",
       " tensor(1.5226e-09),\n",
       " tensor(0.0038),\n",
       " tensor(0.0029),\n",
       " tensor(0.0023),\n",
       " tensor(0.0035),\n",
       " tensor(0.0029),\n",
       " tensor(0.0014),\n",
       " tensor(0.0385),\n",
       " tensor(0.0037),\n",
       " tensor(9.2489e-05),\n",
       " tensor(0.0039),\n",
       " tensor(0.0077),\n",
       " tensor(0.0238),\n",
       " tensor(0.0029),\n",
       " tensor(0.0015),\n",
       " tensor(0.0153),\n",
       " tensor(0.0040),\n",
       " tensor(0.0072),\n",
       " tensor(0.0080),\n",
       " tensor(0.0046),\n",
       " tensor(0.0016),\n",
       " tensor(0.0028),\n",
       " tensor(0.0044),\n",
       " tensor(6.4520e-07),\n",
       " tensor(0.0022),\n",
       " tensor(0.0001),\n",
       " tensor(0.0045),\n",
       " tensor(0.0056),\n",
       " tensor(0.0008),\n",
       " tensor(0.0045),\n",
       " tensor(0.0084),\n",
       " tensor(0.0021),\n",
       " tensor(0.0041),\n",
       " tensor(0.0024),\n",
       " tensor(0.0128),\n",
       " tensor(0.0071),\n",
       " tensor(0.0034),\n",
       " tensor(0.0223),\n",
       " tensor(0.0089),\n",
       " tensor(0.0074),\n",
       " tensor(0.0003),\n",
       " tensor(3.5439e-05),\n",
       " tensor(0.0068),\n",
       " tensor(0.0035),\n",
       " tensor(0.0242),\n",
       " tensor(0.0036),\n",
       " tensor(0.0007),\n",
       " tensor(0.0084),\n",
       " tensor(0.0219),\n",
       " tensor(0.0021),\n",
       " tensor(0.0031),\n",
       " tensor(0.0122),\n",
       " tensor(0.0065),\n",
       " tensor(0.0051),\n",
       " tensor(0.0018),\n",
       " tensor(7.6086e-06),\n",
       " tensor(0.0074),\n",
       " tensor(0.0082),\n",
       " tensor(0.0005),\n",
       " tensor(0.0096),\n",
       " tensor(0.0073),\n",
       " tensor(0.1481),\n",
       " tensor(0.0144),\n",
       " tensor(0.0065),\n",
       " tensor(0.0003),\n",
       " tensor(0.0052),\n",
       " tensor(0.0070),\n",
       " tensor(0.0132),\n",
       " tensor(0.0056),\n",
       " tensor(0.0073),\n",
       " tensor(0.0023),\n",
       " tensor(0.0089),\n",
       " tensor(0.0166),\n",
       " tensor(0.0011),\n",
       " tensor(0.0120),\n",
       " tensor(0.0049),\n",
       " tensor(0.0005),\n",
       " tensor(0.0356),\n",
       " tensor(0.0238),\n",
       " tensor(1.2409e-05),\n",
       " tensor(0.0055),\n",
       " tensor(0.0025),\n",
       " tensor(0.0056),\n",
       " tensor(0.0029),\n",
       " tensor(0.0045),\n",
       " tensor(0.0037),\n",
       " tensor(0.0005),\n",
       " tensor(0.0234),\n",
       " tensor(0.0012),\n",
       " tensor(0.0019),\n",
       " tensor(0.0079),\n",
       " tensor(0.0033),\n",
       " tensor(0.0040),\n",
       " tensor(0.0020),\n",
       " tensor(2.9110e-05),\n",
       " tensor(0.0197),\n",
       " tensor(0.0082),\n",
       " tensor(0.0002),\n",
       " tensor(0.0008),\n",
       " tensor(0.0059),\n",
       " tensor(0.0055),\n",
       " tensor(0.0272),\n",
       " tensor(0.0068),\n",
       " tensor(0.0115),\n",
       " tensor(0.0196),\n",
       " tensor(0.0081),\n",
       " tensor(0.0022),\n",
       " tensor(0.0049),\n",
       " tensor(0.0002),\n",
       " tensor(8.3356e-05),\n",
       " tensor(0.0096),\n",
       " tensor(0.0209),\n",
       " tensor(0.0074),\n",
       " tensor(0.0039),\n",
       " tensor(0.0022),\n",
       " tensor(0.0034),\n",
       " tensor(0.0268),\n",
       " tensor(0.0028),\n",
       " tensor(0.0091),\n",
       " tensor(0.0181),\n",
       " tensor(0.0055),\n",
       " tensor(0.0005),\n",
       " tensor(0.0021),\n",
       " tensor(0.0009),\n",
       " tensor(8.2662e-07),\n",
       " tensor(0.0014),\n",
       " tensor(0.0044),\n",
       " tensor(0.0005),\n",
       " tensor(0.0043),\n",
       " tensor(2.2784e-06),\n",
       " tensor(0.0164),\n",
       " tensor(0.0048),\n",
       " tensor(0.0007),\n",
       " tensor(8.0545e-10),\n",
       " tensor(0.0016),\n",
       " tensor(0.0014),\n",
       " tensor(0.0181),\n",
       " tensor(0.0061),\n",
       " tensor(0.0024),\n",
       " tensor(0.0139),\n",
       " tensor(0.0052),\n",
       " tensor(0.0068),\n",
       " tensor(0.0023),\n",
       " tensor(0.0005),\n",
       " tensor(0.0028),\n",
       " tensor(0.0042),\n",
       " tensor(0.0050),\n",
       " tensor(0.0062),\n",
       " tensor(0.0016),\n",
       " tensor(0.0147),\n",
       " tensor(0.0114),\n",
       " tensor(0.0029),\n",
       " tensor(0.0028),\n",
       " tensor(0.0002),\n",
       " tensor(0.0139),\n",
       " tensor(0.0009),\n",
       " tensor(0.0073),\n",
       " tensor(0.0303),\n",
       " tensor(0.0014),\n",
       " tensor(0.0117),\n",
       " tensor(0.0052),\n",
       " tensor(0.0002),\n",
       " tensor(3.8124e-05),\n",
       " tensor(0.0057),\n",
       " tensor(0.0106),\n",
       " tensor(0.0068),\n",
       " tensor(5.0013e-05),\n",
       " tensor(0.0024),\n",
       " tensor(0.0007),\n",
       " tensor(0.0003),\n",
       " tensor(5.4348e-08),\n",
       " tensor(0.0044),\n",
       " tensor(0.0026),\n",
       " tensor(0.0165),\n",
       " tensor(0.0006),\n",
       " tensor(0.0033),\n",
       " tensor(0.0049),\n",
       " tensor(0.0086),\n",
       " tensor(0.0042),\n",
       " tensor(0.0516),\n",
       " tensor(0.0051),\n",
       " tensor(0.0008),\n",
       " tensor(0.0192),\n",
       " tensor(0.0058),\n",
       " tensor(4.2482e-06),\n",
       " tensor(0.0055),\n",
       " tensor(0.0022),\n",
       " tensor(0.0041),\n",
       " tensor(0.0047),\n",
       " tensor(0.0004),\n",
       " tensor(0.0092),\n",
       " tensor(7.4959e-05),\n",
       " tensor(0.0125),\n",
       " tensor(0.0002),\n",
       " tensor(0.0015),\n",
       " tensor(0.0033),\n",
       " tensor(0.0587),\n",
       " tensor(0.0069),\n",
       " tensor(0.0017),\n",
       " tensor(0.0038),\n",
       " tensor(0.0083),\n",
       " tensor(0.0181),\n",
       " tensor(0.0048),\n",
       " tensor(0.0004),\n",
       " tensor(0.0003),\n",
       " tensor(0.0489),\n",
       " tensor(0.0042),\n",
       " tensor(0.0003),\n",
       " tensor(0.0018),\n",
       " tensor(0.0006),\n",
       " tensor(0.0118),\n",
       " tensor(0.0016),\n",
       " tensor(0.0005),\n",
       " tensor(0.0016),\n",
       " tensor(0.0043),\n",
       " tensor(0.0018),\n",
       " tensor(0.0055),\n",
       " tensor(0.0036),\n",
       " tensor(0.0127),\n",
       " tensor(0.0013),\n",
       " tensor(0.0040),\n",
       " tensor(0.0006),\n",
       " tensor(0.0017),\n",
       " tensor(0.0064),\n",
       " tensor(0.0015),\n",
       " tensor(0.0027),\n",
       " tensor(0.0005),\n",
       " tensor(0.0005),\n",
       " tensor(0.0003),\n",
       " tensor(0.0020),\n",
       " tensor(0.0002),\n",
       " tensor(0.0045),\n",
       " tensor(0.0042),\n",
       " tensor(0.0045),\n",
       " tensor(0.0012),\n",
       " tensor(4.7011e-05),\n",
       " tensor(0.0018),\n",
       " tensor(8.2360e-05),\n",
       " tensor(1.9250e-08),\n",
       " tensor(0.0094),\n",
       " tensor(3.0463e-07),\n",
       " tensor(0.0008),\n",
       " tensor(0.0073),\n",
       " tensor(0.0055),\n",
       " tensor(0.0043),\n",
       " tensor(0.0003),\n",
       " tensor(0.0004),\n",
       " tensor(0.0001),\n",
       " tensor(0.0002),\n",
       " tensor(0.0051),\n",
       " tensor(0.0655),\n",
       " tensor(0.0046),\n",
       " tensor(0.0009),\n",
       " tensor(0.0012),\n",
       " tensor(5.6743e-05),\n",
       " tensor(0.0007),\n",
       " tensor(0.0039),\n",
       " tensor(0.0080),\n",
       " tensor(0.0001),\n",
       " tensor(0.0017),\n",
       " tensor(0.0649),\n",
       " tensor(8.2139e-07),\n",
       " tensor(0.0065),\n",
       " tensor(0.0001),\n",
       " tensor(1.9187e-09),\n",
       " tensor(0.0010),\n",
       " tensor(0.0003),\n",
       " tensor(0.0026),\n",
       " tensor(0.0035),\n",
       " tensor(7.0437e-05),\n",
       " tensor(0.0029),\n",
       " tensor(0.0033),\n",
       " tensor(0.0006),\n",
       " tensor(0.0010),\n",
       " tensor(0.0041),\n",
       " tensor(0.0129),\n",
       " tensor(1.2964e-05),\n",
       " tensor(0.0013),\n",
       " tensor(0.0074),\n",
       " tensor(0.0155),\n",
       " tensor(0.0009),\n",
       " tensor(0.0003),\n",
       " tensor(0.0194),\n",
       " tensor(0.0251),\n",
       " tensor(1.8347e-05),\n",
       " tensor(5.1400e-05),\n",
       " tensor(0.0003),\n",
       " tensor(0.0038),\n",
       " tensor(0.1382),\n",
       " tensor(0.0179),\n",
       " tensor(0.0048),\n",
       " tensor(0.0033),\n",
       " tensor(2.0687e-07),\n",
       " tensor(0.0007),\n",
       " tensor(0.0053),\n",
       " tensor(0.0003),\n",
       " tensor(0.0813),\n",
       " tensor(0.0005),\n",
       " tensor(1.2215e-05),\n",
       " tensor(9.7439e-07),\n",
       " tensor(0.0025),\n",
       " tensor(0.0007),\n",
       " tensor(0.0032),\n",
       " tensor(0.0010),\n",
       " tensor(1.8353e-06),\n",
       " tensor(3.0634e-08),\n",
       " tensor(0.0022),\n",
       " tensor(0.0085),\n",
       " tensor(0.0070),\n",
       " tensor(0.0013),\n",
       " tensor(0.0251),\n",
       " tensor(0.0048),\n",
       " tensor(0.0360),\n",
       " tensor(6.8599e-05),\n",
       " tensor(0.0009),\n",
       " tensor(0.0039),\n",
       " tensor(0.0016),\n",
       " tensor(0.0049),\n",
       " tensor(0.0102),\n",
       " tensor(0.0014),\n",
       " tensor(0.0039),\n",
       " tensor(0.0110),\n",
       " tensor(0.0019),\n",
       " tensor(0.0034),\n",
       " tensor(0.0018),\n",
       " tensor(0.0083),\n",
       " tensor(0.0017),\n",
       " tensor(0.0438),\n",
       " tensor(0.0150),\n",
       " tensor(3.4073e-07),\n",
       " tensor(0.0021),\n",
       " tensor(0.0009),\n",
       " tensor(0.0022),\n",
       " tensor(0.0002),\n",
       " tensor(0.0050),\n",
       " tensor(0.0177),\n",
       " tensor(0.0050),\n",
       " tensor(0.0053),\n",
       " tensor(0.0080),\n",
       " tensor(0.0001),\n",
       " tensor(0.0003),\n",
       " tensor(0.0270),\n",
       " tensor(0.0059),\n",
       " tensor(0.0021),\n",
       " tensor(0.0088),\n",
       " tensor(0.0395),\n",
       " tensor(0.0008),\n",
       " tensor(2.7542e-05),\n",
       " tensor(0.0068),\n",
       " tensor(0.0007),\n",
       " tensor(0.0006),\n",
       " tensor(0.1068),\n",
       " tensor(0.0020),\n",
       " tensor(0.0093),\n",
       " tensor(0.0057),\n",
       " tensor(0.0003),\n",
       " tensor(0.0077),\n",
       " tensor(0.0046),\n",
       " tensor(0.0006),\n",
       " tensor(0.0075),\n",
       " tensor(0.0021),\n",
       " tensor(0.0383),\n",
       " tensor(0.0058),\n",
       " tensor(0.0007),\n",
       " tensor(0.0003),\n",
       " tensor(0.0203),\n",
       " tensor(0.0512),\n",
       " tensor(0.0367),\n",
       " tensor(0.0003),\n",
       " tensor(0.0012),\n",
       " tensor(0.0055),\n",
       " tensor(0.0035),\n",
       " tensor(0.0352),\n",
       " tensor(0.0021)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9a326f",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a3e88bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=8, n_estimators=1000, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=8, n_estimators=1000, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=8, n_estimators=1000, random_state=42)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model hyperparameters optimized using Grid-Search CV on 300 randomly selected sequences\n",
    "# 9,699 amino acid instances\n",
    "\n",
    "# Train Random Forest Classifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(criterion='gini', max_depth=8,max_features='sqrt',n_estimators = 1000,random_state=42)\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ecc2c42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC(C=10, class_weight=&#x27;balanced&#x27;, dual=True, loss=&#x27;hinge&#x27;,\n",
       "          max_iter=200000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC(C=10, class_weight=&#x27;balanced&#x27;, dual=True, loss=&#x27;hinge&#x27;,\n",
       "          max_iter=200000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC(C=10, class_weight='balanced', dual=True, loss='hinge',\n",
       "          max_iter=200000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model hyperparameters optimized using Grid-Search CV on 300 randomly selected sequences\n",
    "# 9,699 amino acid instances\n",
    "\n",
    "# Train Linear SVC\n",
    "\n",
    "linear_svc = LinearSVC(C=10, class_weight='balanced', dual=True, loss='hinge',max_iter=200000)\n",
    "linear_svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "04a43d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=100, max_iter=200000, solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=100, max_iter=200000, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=100, max_iter=200000, solver='saga')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model hyperparameters optimized using Grid-Search CV on 300 randomly selected sequences\n",
    "# 9,699 amino acid instances\n",
    "\n",
    "# Train Logistic Regression\n",
    "\n",
    "lr_clf = LogisticRegression(C=100, max_iter=200000, solver='saga')\n",
    "lr_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16963e8",
   "metadata": {},
   "source": [
    "## Test a randomly generated sequence against trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "33a64f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of standard amino acids (excluding stop codons)\n",
    "amino_acids = ['A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I', \n",
    "               'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V']\n",
    "\n",
    "# Generate a random sequence of 300 amino acids\n",
    "random_seq = ''.join(random.choices(amino_acids, k=300))\n",
    "\n",
    "rand_protein_data = {}\n",
    "rand_protein_data['random1'] = random_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c75d8b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get random sequence embedding\n",
    "\n",
    "random_embedding = generate_embeddings('random1',rand_protein_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "72389c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get random sequence embeddings\n",
    "\n",
    "random_x = []\n",
    "\n",
    "for res_1 in random.sample(range(300),80):\n",
    "    for res_2 in random.sample(range(300),80):\n",
    "        if res_1==res_2:\n",
    "            continue\n",
    "        else:\n",
    "#             print(res_1,res_2)\n",
    "            random_x.append(get_x_y(random_embedding, res_1, res_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1c548609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a subset of amino acid pair instances\n",
    "n = 5000\n",
    "random_x_test = random.sample(random_x, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8929a756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "\n",
    "rf_rand_y_pred = rf_clf.predict(random_x_test)\n",
    "# lr_rand_y_pred = lr_clf.predict(random_x_test)\n",
    "# svc_rand_y_pred = linear_svc.predict(random_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2711514c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf_rand_y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m rf_false_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      2\u001b[0m rf_true_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m rf_rand_y_pred:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m      6\u001b[0m         rf_false_count\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rf_rand_y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "rf_false_count = 0\n",
    "rf_true_count = 0\n",
    "\n",
    "for i in rf_rand_y_pred:\n",
    "    if i == False:\n",
    "        rf_false_count+=1\n",
    "    else:\n",
    "        rf_true_count+=1\n",
    "\n",
    "rf_accuracy = rf_false_count/n*100\n",
    "print(f'Random Forest Accuracy: {rf_accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c1264234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logisitc Regression Accuracy: 96.82%\n"
     ]
    }
   ],
   "source": [
    "lr_false_count = 0\n",
    "lr_true_count = 0\n",
    "\n",
    "for i in lr_rand_y_pred:\n",
    "    if i == False:\n",
    "        lr_false_count+=1\n",
    "    else:\n",
    "        lr_true_count+=1\n",
    "\n",
    "lr_accuracy = lr_false_count/n*100\n",
    "print(f'Logistic Regression Accuracy: {lr_accuracy}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4594fcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC Accuracy: 97.76%\n"
     ]
    }
   ],
   "source": [
    "svc_false_count = 0\n",
    "svc_true_count = 0\n",
    "\n",
    "for i in svc_rand_y_pred:\n",
    "    if i == False:\n",
    "        svc_false_count+=1\n",
    "    else:\n",
    "        svc_true_count+=1\n",
    "\n",
    "svc_accuracy = svc_false_count/n*100\n",
    "print(f'Linear SVC Accuracy: {svc_accuracy}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
